{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171e28f8",
   "metadata": {},
   "source": [
    "# <font face = 'Palatino Linotype' color = '#274472'> Real Estate Valuation using Machine Learning <font/>\n",
    "### <font face = 'Palatino Linotype' color = '#5885AF'> Data Scientists: Paolo Hilado and Alison Danvers<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f4ee2",
   "metadata": {},
   "source": [
    "<font face = 'Palatino Linotype' color = '#5885AF'> Scenario:<font/>\n",
    "   \n",
    "<font face = 'Palatino Linotype'> Data Scientists were tasked with developing a machine learning model that will be used to estimate real estate based on provided explanatory variables. It is based on market historical dataset of real estate valuation collected from Sindian Dist. New Taipei City. <font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404805e",
   "metadata": {},
   "source": [
    "<font face = 'Palatino Linotype' color = '#5885AF'> Business Understanding:<font/>\n",
    "   \n",
    "<font face = 'Palatino Linotype'> Sindian District New Taipei City is an urbanized city in Taiwan. In this project the explanatory variables considered to estimate house price include transaction date, house age, distance from the nearest Mass Rapid Transit (MRT), number of convenience stores nearby, and the latitude and longitude of the property.<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532e6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # used for training and testing a model\n",
    "import math # used to separate the whole number from the decimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be94b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.916667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012.916667</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013.583333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  X1 transaction date  X2 house age  \\\n",
       "0   1          2012.916667          32.0   \n",
       "1   2          2012.916667          19.5   \n",
       "2   3          2013.583333          13.3   \n",
       "3   4          2013.500000          13.3   \n",
       "4   5          2012.833333           5.0   \n",
       "\n",
       "   X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       "0                                84.87882                               10   \n",
       "1                               306.59470                                9   \n",
       "2                               561.98450                                5   \n",
       "3                               561.98450                                5   \n",
       "4                               390.56840                                5   \n",
       "\n",
       "   X5 latitude  X6 longitude  Y house price of unit area  \n",
       "0     24.98298     121.54024                        37.9  \n",
       "1     24.98034     121.53951                        42.2  \n",
       "2     24.98746     121.54391                        47.3  \n",
       "3     24.98746     121.54391                        54.8  \n",
       "4     24.97937     121.54245                        43.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"DataSet.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2cf3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   No                                      414 non-null    int64  \n",
      " 1   X1 transaction date                     414 non-null    float64\n",
      " 2   X2 house age                            414 non-null    float64\n",
      " 3   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 4   X4 number of convenience stores         414 non-null    int64  \n",
      " 5   X5 latitude                             414 non-null    float64\n",
      " 6   X6 longitude                            414 non-null    float64\n",
      " 7   Y house price of unit area              414 non-null    float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 26.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8402c04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                                        False\n",
       "X1 transaction date                       False\n",
       "X2 house age                              False\n",
       "X3 distance to the nearest MRT station    False\n",
       "X4 number of convenience stores           False\n",
       "X5 latitude                               False\n",
       "X6 longitude                              False\n",
       "Y house price of unit area                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.eq(' ').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5532821",
   "metadata": {},
   "source": [
    "<font face = 'Palatino Linotype' color = '#5885AF'> Data Understanding:<font/>\n",
    "   \n",
    "<font face = 'Palatino Linotype'> The dataframe has 8 features (7 explanatory variables and 1 outcome variable) and 414 observations. With the given dataset, the transaction date refers to the year and the corresponding month. The decimal values are derived by having the month represented by a number (i.e., January = 1, February =2, etc.) divided by the total number of months in a year. It is presented as a continuous variable in the dataset such that 2013.250 = 2013 March, 2013.500 = 2013 June. The house age is on a per year unit, distance to the nearest MRT station is measured in meters, the number of convenience stores refers to those accessible within a given area in a walking distance, and the latitude and longitude refers to the coordinates of the property. It can also be observed that there are no missing or empty cases in the dataframe.<font/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f66e7c",
   "metadata": {},
   "source": [
    "<font face = 'Palatino Linotype' color = '#5885AF'> Data Preparation<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11164c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013.583333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
       "0          2012.916667          32.0                                84.87882   \n",
       "1          2012.916667          19.5                               306.59470   \n",
       "2          2013.583333          13.3                               561.98450   \n",
       "3          2013.500000          13.3                               561.98450   \n",
       "4          2012.833333           5.0                               390.56840   \n",
       "\n",
       "   X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
       "0                               10     24.98298     121.54024   \n",
       "1                                9     24.98034     121.53951   \n",
       "2                                5     24.98746     121.54391   \n",
       "3                                5     24.98746     121.54391   \n",
       "4                                5     24.97937     121.54245   \n",
       "\n",
       "   Y house price of unit area  \n",
       "0                        37.9  \n",
       "1                        42.2  \n",
       "2                        47.3  \n",
       "3                        54.8  \n",
       "4                        43.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the irrelevant feature for developing the machine learning model.\n",
    "df = df.drop(['No'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120f18e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t.date</th>\n",
       "      <th>h.age</th>\n",
       "      <th>dist.mrt</th>\n",
       "      <th>no.stores</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013.583333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t.date  h.age   dist.mrt  no.stores       lat       long  price\n",
       "0  2012.916667   32.0   84.87882         10  24.98298  121.54024   37.9\n",
       "1  2012.916667   19.5  306.59470          9  24.98034  121.53951   42.2\n",
       "2  2013.583333   13.3  561.98450          5  24.98746  121.54391   47.3\n",
       "3  2013.500000   13.3  561.98450          5  24.98746  121.54391   54.8\n",
       "4  2012.833333    5.0  390.56840          5  24.97937  121.54245   43.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide shorter names for the columns.\n",
    "df = df.rename(columns = {'X1 transaction date':'t.date', 'X2 house age':'h.age', \n",
    "                    'X3 distance to the nearest MRT station':'dist.mrt', \n",
    "                    'X4 number of convenience stores':'no.stores',\n",
    "                    'X5 latitude':'lat', \n",
    "                    'X6 longitude':'long', \n",
    "                    'Y house price of unit area':'price'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e60e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records for the train set is 289.\n",
      "The number of records for the test set is 125.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test sets.\n",
    "# Given 6 explanatory variables we would at need > 98 observations for\n",
    "# training a regression model (Tabachnick and Fidell, 2013). The 70-30 split\n",
    "# will be used for this project. \n",
    "train, test = train_test_split(df, test_size=0.30, random_state=0)\n",
    "print(f'''The number of records for the train set is {len(train)}.\n",
    "The number of records for the test set is {len(test)}.''')\n",
    "# Source: Tabachnick, B.G.,Fidell, L.S., 2013. Using Multivariate Statistics, \n",
    "#         6th ed. Pearson Education, Inc., Boston. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2193cb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t.date</th>\n",
       "      <th>h.age</th>\n",
       "      <th>dist.mrt</th>\n",
       "      <th>no.stores</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>26.4</td>\n",
       "      <td>335.52730</td>\n",
       "      <td>6</td>\n",
       "      <td>24.97960</td>\n",
       "      <td>121.54140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2013.416667</td>\n",
       "      <td>6.4</td>\n",
       "      <td>90.45606</td>\n",
       "      <td>9</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.54310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>3.9</td>\n",
       "      <td>49.66105</td>\n",
       "      <td>8</td>\n",
       "      <td>24.95836</td>\n",
       "      <td>121.53756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3947.94500</td>\n",
       "      <td>0</td>\n",
       "      <td>24.94783</td>\n",
       "      <td>121.50243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>39.7</td>\n",
       "      <td>333.36790</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98016</td>\n",
       "      <td>121.53932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          t.date  h.age    dist.mrt  no.stores       lat       long\n",
       "294  2013.500000   26.4   335.52730          6  24.97960  121.54140\n",
       "96   2013.416667    6.4    90.45606          9  24.97433  121.54310\n",
       "377  2013.333333    3.9    49.66105          8  24.95836  121.53756\n",
       "89   2013.500000   23.0  3947.94500          0  24.94783  121.50243\n",
       "233  2013.333333   39.7   333.36790          9  24.98016  121.53932"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the explanatory variables from the outcome variable.\n",
    "x_train = train.drop(['price'], axis = 1)\n",
    "y_train = train['price']\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d700a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t.date</th>\n",
       "      <th>h.age</th>\n",
       "      <th>dist.mrt</th>\n",
       "      <th>no.stores</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>10.3</td>\n",
       "      <td>211.4473</td>\n",
       "      <td>1</td>\n",
       "      <td>24.97417</td>\n",
       "      <td>121.52999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4527.6870</td>\n",
       "      <td>0</td>\n",
       "      <td>24.94741</td>\n",
       "      <td>121.49628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>34.5</td>\n",
       "      <td>324.9419</td>\n",
       "      <td>6</td>\n",
       "      <td>24.97814</td>\n",
       "      <td>121.54170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2013.333333</td>\n",
       "      <td>25.6</td>\n",
       "      <td>4519.6900</td>\n",
       "      <td>0</td>\n",
       "      <td>24.94826</td>\n",
       "      <td>121.49587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>14.4</td>\n",
       "      <td>169.9803</td>\n",
       "      <td>1</td>\n",
       "      <td>24.97369</td>\n",
       "      <td>121.52979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          t.date  h.age   dist.mrt  no.stores       lat       long\n",
       "356  2012.833333   10.3   211.4473          1  24.97417  121.52999\n",
       "170  2013.333333   24.0  4527.6870          0  24.94741  121.49628\n",
       "224  2013.333333   34.5   324.9419          6  24.97814  121.54170\n",
       "331  2013.333333   25.6  4519.6900          0  24.94826  121.49587\n",
       "306  2013.500000   14.4   169.9803          1  24.97369  121.52979"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the explanatory variables from the outcome variable.\n",
    "x_test = test.drop(['price'], axis = 1)\n",
    "y_test = test['price']\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c20133f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all the continuous variables.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assigning feature labels to variable continuous_vars.\n",
    "continuous_vars = ['t.date','h.age', 'dist.mrt', 'no.stores','lat','long']\n",
    "\n",
    "# Initialize StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them.\n",
    "x_train[continuous_vars] = scaler.fit_transform(x_train[continuous_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e40520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all the continuous variables.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your data in a DataFrame called df with continuous variables\n",
    "# Replace continuous_vars with the names of your continuous variables\n",
    "continuous_vars = ['t.date','h.age', 'dist.mrt', 'no.stores','lat','long']\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them\n",
    "x_test[continuous_vars] = scaler.transform(x_test[continuous_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62dc7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature       VIF\n",
      "0      const  1.000000\n",
      "1     t.date  1.021891\n",
      "2      h.age  1.013221\n",
      "3   dist.mrt  4.281389\n",
      "4  no.stores  1.660112\n",
      "5        lat  1.566731\n",
      "6       long  2.840975\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Checking for Multicollinearity among continuous variables using the Variance Inflation Factor.\n",
    "# Results show that there is no multicollinearity as the VIF for the continuous variables\n",
    "# are less than 5.\n",
    "X = sm.add_constant(x_train.iloc[:,0:6]) \n",
    "# Calculate VIF for each predictor variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0da8159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 10.0, 'solver': 'sag'}\n",
      "Root Mean Squared Error on train set: 8.94\n"
     ]
    }
   ],
   "source": [
    "# Training a machine learning model for a regression problem using the x_train dataset and the\n",
    "# outcome variable y_train.\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge # You can replace Ridge with any other regression model you want to tune\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming you have your features in X and target variable in y\n",
    "\n",
    "# Define Ridge regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],  # Regularization strength (L2 penalty)\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']  # Solver options\n",
    "}\n",
    "# Perform cross-validation grid search\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5) # cv=5 for 5-fold cross-validation\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the train set using RMSE\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on train set:\", np.round(rmse_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70812e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 18.11\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_train])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_train_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_train)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))\n",
    "# trying out other models due to terrible performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb1de1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1}\n",
      "Root Mean Squared Error on train set: 8.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Assuming you have your features in X and target variable in y\n",
    "\n",
    "# Define the Lasso regression model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Perform cross-validation grid search\n",
    "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the train set using RMSE\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on train set:\", np.round(rmse_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da31a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 18.13\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_train])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_train_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_train)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))\n",
    "# trying out other models due to terrible performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af63d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'l1_ratio': 0.2, 'max_iter': 5}\n",
      "Root Mean Squared Error on train set: 8.95\n"
     ]
    }
   ],
   "source": [
    "# Performing Elastic Net Regression\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# (You should replace this with your own dataset)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for Elastic Net\n",
    "parametersGrid = {\n",
    "    \"max_iter\": [1, 5, 10],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1)\n",
    "}\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "eNet = ElasticNet()\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search  = GridSearchCV(eNet, parametersGrid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the train set using RMSE\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on train set:\", np.round(rmse_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47eb08e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 18.12\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_train])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_train_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_train)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))\n",
    "# trying out other models due to terrible performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2306603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Root Mean Squared Error on train set: 5.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define Random Forest regressor\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "# Evaluate the best model on the train set using RMSE\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on train set:\", np.round(rmse_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73cfbc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 9.07\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_train])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_train_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_train)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))\n",
    "# trying out other models due to terrible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d4cf1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error on test set: 7.07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set using RMSE\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on test set:\", np.round(rmse_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b5ec733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 14.88\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_test])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_test_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_test)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))\n",
    "# trying out other models due to terrible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d94847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'colsample_bytree': 0.8, 'gamma': 0.2, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'reg_alpha': 0, 'reg_lambda': 0.5, 'subsample': 0.9}\n",
      "Root Mean Squared Error on train set: 4.33\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the XGBoost regressor\n",
    "xgb_regressor = xgb.XGBRegressor()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Perform cross-validation grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the train set using RMSE\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on train set:\", np.round(rmse_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0037358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error on test set: 7.08\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set using RMSE\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)  # RMSE on train set\n",
    "print(\"Root Mean Squared Error on test set:\", np.round(rmse_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97cdf6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Absolute Percentage Error (WMAPE): 9.15\n"
     ]
    }
   ],
   "source": [
    "# Checking model performance using the weighted mean absolute percentage error.\n",
    "\n",
    "# Define the actual values (y_true) and predicted values (y_pred) for the test set\n",
    "# Assuming you have already obtained these from your model\n",
    "y_true = np.array([y_train])  # Replace [actual_values] with the actual values from your test set\n",
    "y_pred = np.array([y_train_pred])  # Replace [predicted_values] with the predicted values from your model\n",
    "\n",
    "# Compute the absolute percentage errors\n",
    "absolute_percentage_errors = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "# Compute the weighted mean absolute percentage error (WMAPE)\n",
    "mape = (np.sum(absolute_percentage_errors) / len(y_train)) * 100\n",
    "\n",
    "print(\"Weighted Mean Absolute Percentage Error (WMAPE):\", np.round(mape,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6bfbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the Random Forest Model.\n",
    "import pickle\n",
    "pickle.dump(best_model, open('XGBmodel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cb202",
   "metadata": {},
   "source": [
    "### Decision:\n",
    "\n",
    "Having a an almost the same RMSE (7.08) but a lower WMAPE (9.15) on the test data compared to Random Forest Regressor, the XGBoost Model is preferred to provide estimates on housing cost given the explanatory variables such as transaction date, house age, its distance to the MRT station, number of nearby convenience store, latitude, and longitude.This is the model saved for future use in estimating house prices given the identified explanatory variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
